{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9_KXHpwlPFL"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain"
      ],
      "metadata": {
        "id": "QOB0rbH4laGV"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "vlM9hc8l3gQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "ljCWqPip59Vd"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \" \" # insert your API_TOKEN here\n",
        "\n",
        "#openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "zBncGFh426-y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.llms import OpenAI\n",
        "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n"
      ],
      "metadata": {
        "id": "edKB7HhP27IC"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The LLM takes a prompt as an input and outputs a completion\n",
        "\n",
        "prompt = \"Alice has a parrot.What animal is Alice's pet?\"\n",
        "completion = llm(prompt)\n",
        "print(completion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-3G7L_j27Kw",
        "outputId": "8249bf04-26dc-4c4f-a93a-be453bf87680"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Alice's pet is a parrot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Promp Template"
      ],
      "metadata": {
        "id": "MkT7DhRAvLDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " LangChain provides you PromptTemplates, which help you construct prompts from multiple components.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PRc_FgeZluso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"What is a good name for a company that makes {product}?\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=template,\n",
        ")\n",
        "prompt.format(product=\"Shoes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WXzqND9m27OC",
        "outputId": "8d63b13c-46da-49ca-dc6e-7df4242bcade"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes Shoes?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm = llm,\n",
        "                  prompt = prompt)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "chain.run(\"Shoes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S9azRGULn5mp",
        "outputId": "fed8919b-53b4-457f-a075-bf5b6755d429"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SoleCraft Footwear'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If we want to use the output of this first LLM as the input for a second LLM, we can use a **SimpleSequentialChain:**"
      ],
      "metadata": {
        "id": "8PAHQ_FLoR5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "\n",
        "# Define the first chain as in the previous code example\n",
        "# ...\n",
        "\n",
        "# Create a second chain with a prompt template and an LLM\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"company_name\"],\n",
        "    template=\"Write a catchphrase for the following company: {company_name}\",\n",
        ")\n",
        "\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
        "\n",
        "# Combine the first and the second chain\n",
        "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
        "\n",
        "# Run the chain specifying only the input variable for the first chain.\n",
        "catchphrase = overall_chain.run(\"Kites\")"
      ],
      "metadata": {
        "id": "SeFLXAs87Hvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8bdef71-6de5-4f79-a0ce-4e7653a5b5ee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mSkySail Kites\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\"Fly high with SkySail Kites, where the sky's the limit for fun and adventure!\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Memory: Remembering previous conversations\n",
        "\n"
      ],
      "metadata": {
        "id": "jNwqnj7CV1OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import ConversationChain\n",
        "\n",
        "conversation = ConversationChain(llm=llm, verbose=False)\n",
        "\n",
        "conversation.predict(input=\"Alice has a parrot.\")\n",
        "\n",
        "conversation.predict(input=\"Bob has two cats.\")\n",
        "\n",
        "conversation.predict(input=\"How many pets do Alice and Bob have?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ulNi0t0ppaE0",
        "outputId": "2c6434d6-fbfb-444b-ffae-4a27d6b7af3f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Alice has a parrot and Bob has two cats, so together they have three pets.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents: Accessing other tools"
      ],
      "metadata": {
        "id": "lcsFvpGjrVyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import tool\n",
        "#custom tool\n",
        "\n",
        "@tool\n",
        "def get_word_length(word: str) -> int:\n",
        "    \"\"\"Returns the length of a word.\"\"\"\n",
        "    return len(word)\n",
        "\n",
        "tools = [get_word_length]"
      ],
      "metadata": {
        "id": "5YfM91a_tyS4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import OpenAIFunctionsAgent\n",
        "prompt = OpenAIFunctionsAgent.create_prompt()"
      ],
      "metadata": {
        "id": "aVykRImhtyfg"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)  #to create prompt"
      ],
      "metadata": {
        "id": "4E_jfowkt7le"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "SqAGsvKZul47"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run(\"how many letters in the word Edureka?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "aL1xAeOXt7op",
        "outputId": "180ab9e6-5361-4f5e-acaa-75fe4038e6ff"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_word_length` with `{'word': 'Edureka'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m7\u001b[0m\u001b[32;1m\u001b[1;3mThere are 7 letters in the word \"Edureka\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are 7 letters in the word \"Edureka\".'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M1GLgJ_lzGpT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}